{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Probabilistic Feature Subset Selection with Ensemble Models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:24:59.990648Z",
     "start_time": "2025-01-14T16:24:59.431122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import compute_feature_frequency, load_uci_dataset, train_ensemble_models"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## UCI Heart Failure Clinical Records Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:01.407861Z",
     "start_time": "2025-01-14T16:24:59.994273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "heart_failure_clinical_records = load_uci_dataset(\"data/heart_failure.csv\", repo_id=519, verbose=True)\n",
    "print(\"Number of samples:\", len(heart_failure_clinical_records))\n",
    "heart_failure_clinical_records.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 519, 'name': 'Heart Failure Clinical Records', 'repository_url': 'https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records', 'data_url': 'https://archive.ics.uci.edu/static/public/519/data.csv', 'abstract': 'This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 299, 'num_features': 12, 'feature_types': ['Integer', 'Real'], 'demographics': ['Age', 'Sex'], 'target_col': ['death_event'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5Z89R', 'creators': [], 'intro_paper': {'ID': 286, 'type': 'NATIVE', 'title': 'Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone', 'authors': 'D. Chicco, Giuseppe Jurman', 'venue': 'BMC Medical Informatics and Decision Making', 'year': 2020, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/e64579d8593140396b518682bb3a47ba246684eb', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': '32013925', 'pmcid': None}, 'additional_info': {'summary': 'A detailed description of the dataset can be found in the Dataset section of the following paper: \\r\\n\\r\\nDavide Chicco, Giuseppe Jurman: \"Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone\". BMC Medical Informatics and Decision Making 20, 16 (2020). https://doi.org/10.1186/s12911-020-1023-5 \\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Thirteen (13) clinical features:\\n\\n- age: age of the patient (years)\\n- anaemia: decrease of red blood cells or hemoglobin (boolean)\\n- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)\\n- diabetes: if the patient has diabetes (boolean)\\n- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)\\n- high blood pressure: if the patient has hypertension (boolean)\\n- platelets: platelets in the blood (kiloplatelets/mL)\\n- sex: woman or man (binary)\\n- serum creatinine: level of serum creatinine in the blood (mg/dL)\\n- serum sodium: level of serum sodium in the blood (mEq/L)\\n- smoking: if the patient smokes or not (boolean)\\n- time: follow-up period (days)\\n- [target] death event: if the patient died during the follow-up period (boolean)\\n\\nFor more information, please check Table 1, Table 2, and Table 3 of the following paper: \\n\\nDavide Chicco, Giuseppe Jurman: \"Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone\". BMC Medical Informatics and Decision Making 20, 16 (2020). https://doi.org/10.1186/s12911-020-1023-5 \\n', 'citation': None}}\n",
      "Number of samples: 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  death_event  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>death_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocess Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:01.481111Z",
     "start_time": "2025-01-14T16:25:01.479125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Handle missing values by dropping rows with any missing values\n",
    "heart_failure_clinical_records = heart_failure_clinical_records.dropna()\n",
    "print(\"Number of samples:\", len(heart_failure_clinical_records))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 299\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:01.510547Z",
     "start_time": "2025-01-14T16:25:01.507058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separate features and target after dropping missing values\n",
    "X = heart_failure_clinical_records.iloc[:, :-1]  # All columns except the last\n",
    "y = heart_failure_clinical_records.iloc[:, -1]  # Last column as target\n",
    "\n",
    "# Encode target labels if necessary\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Assign Probabilities to Features using Mutual Information\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:01.526974Z",
     "start_time": "2025-01-14T16:25:01.514383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "probabilities = mutual_info / np.sum(mutual_info)  # Normalize to create a probability distribution\n",
    "\n",
    "print(\"Feature Probabilities (Mutual Information):\")\n",
    "print(probabilities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Probabilities (Mutual Information):\n",
      "[0.0981084  0.         0.02550401 0.         0.11525658 0.\n",
      " 0.         0.16443328 0.03866046 0.         0.03817242 0.51986487]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Multiple Ensembles on Probabilistically Sampled Subsets\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:02.191225Z",
     "start_time": "2025-01-14T16:25:01.547514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_results = train_ensemble_models(X_train, X_test, y_train, y_test, probabilities, n_ensembles=5, n_features_sample=5, random_state=42, verbose=True)\n",
    "\n",
    "results_df = pd.DataFrame(ensemble_results)\n",
    "results_df.groupby(\"Classifier\")[\"Accuracy\"].mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ensemble 1/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8667\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8556\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 2/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8111\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 3/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8667\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 4/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8556\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8333\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8222\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8111\n",
      "\n",
      "Training Ensemble 5/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8000\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8333\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7222\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "AdaBoost               0.835556\n",
       "Gradient Boosting      0.835556\n",
       "LDA                    0.811111\n",
       "Logistic Regression    0.811111\n",
       "Random Forest          0.844444\n",
       "SVM                    0.773333\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Analyze uncertainty in feature importance\n",
    "feature_frequency = compute_feature_frequency(ensemble_results, X_train.shape[1])\n",
    "\n",
    "print(\"\\nFeature Selection Frequency:\")\n",
    "print(feature_frequency)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gMeiCwsvlfh",
    "outputId": "75390383-eab7-49b9-98e0-b168a6cc86fc",
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:02.215005Z",
     "start_time": "2025-01-14T16:25:02.212610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Selection Frequency:\n",
      "[0.6 0.  0.6 0.  0.8 0.  0.  1.  0.6 0.  0.4 1. ]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Assign probabilities to features using interaction scores"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:02.331936Z",
     "start_time": "2025-01-14T16:25:02.271238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Calculate pairwise interaction scores\n",
    "interaction_matrix = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for tree in rf.estimators_:\n",
    "    for feature_idx, importance in enumerate(tree.feature_importances_):\n",
    "        interaction_matrix[feature_idx] += importance\n",
    "\n",
    "interaction_scores = interaction_matrix.sum(axis=1) / rf.n_estimators\n",
    "probabilities = interaction_scores / interaction_scores.sum()\n",
    "\n",
    "print(\"Feature Probabilities (Interaction Scores):\")\n",
    "print(probabilities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Probabilities (Interaction Scores):\n",
      "[0.08910293 0.01823446 0.06889207 0.01136961 0.10625269 0.01338873\n",
      " 0.07031262 0.15944837 0.08441427 0.01277598 0.01005281 0.35575545]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Multiple Ensembles on Probabilistically Sampled Subsets\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:02.993482Z",
     "start_time": "2025-01-14T16:25:02.341921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_results = train_ensemble_models(X_train, X_test, y_train, y_test, probabilities, n_ensembles=5, n_features_sample=5, random_state=42, verbose=True)\n",
    "\n",
    "results_df = pd.DataFrame(ensemble_results)\n",
    "results_df.groupby(\"Classifier\")[\"Accuracy\"].mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ensemble 1/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8333\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8444\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8333\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.6778\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8333\n",
      "\n",
      "Training Ensemble 2/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.7889\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8333\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7222\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8444\n",
      "\n",
      "Training Ensemble 3/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8333\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8222\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.7889\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.6778\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8111\n",
      "\n",
      "Training Ensemble 4/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8000\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8111\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8222\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8333\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.6778\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8222\n",
      "\n",
      "Training Ensemble 5/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8000\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8111\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8111\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.6778\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.7889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "AdaBoost               0.826667\n",
       "Gradient Boosting      0.815556\n",
       "LDA                    0.820000\n",
       "Logistic Regression    0.817778\n",
       "Random Forest          0.815556\n",
       "SVM                    0.686667\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze uncertainty in feature importance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:25:03.026527Z",
     "start_time": "2025-01-14T16:25:03.024287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze uncertainty in feature importance\n",
    "feature_frequency = compute_feature_frequency(ensemble_results, X_train.shape[1])\n",
    "\n",
    "print(\"\\nFeature Selection Frequency:\")\n",
    "print(feature_frequency)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Selection Frequency:\n",
      "[0.6 0.2 0.4 0.  0.2 0.  0.8 0.8 0.6 0.2 0.2 1. ]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ]
}
