{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Probabilistic Feature Subset Selection with Ensemble Models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:47:21.688987Z",
     "start_time": "2025-01-15T10:47:21.051206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import compute_feature_frequency, load_uci_dataset, train_ensemble_models"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## UCI Heart Failure Clinical Records Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:47:27.432669Z",
     "start_time": "2025-01-15T10:47:24.338358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "breast_cancer_clinical_records = load_uci_dataset(\"../data/breast_cancer.csv\", repo_id=15, verbose=True)\n",
    "print(\"Number of samples:\", len(breast_cancer_clinical_records))\n",
    "breast_cancer_clinical_records.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 519, 'name': 'Heart Failure Clinical Records', 'repository_url': 'https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records', 'data_url': 'https://archive.ics.uci.edu/static/public/519/data.csv', 'abstract': 'This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 299, 'num_features': 12, 'feature_types': ['Integer', 'Real'], 'demographics': ['Age', 'Sex'], 'target_col': ['death_event'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5Z89R', 'creators': [], 'intro_paper': {'ID': 286, 'type': 'NATIVE', 'title': 'Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone', 'authors': 'D. Chicco, Giuseppe Jurman', 'venue': 'BMC Medical Informatics and Decision Making', 'year': 2020, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/e64579d8593140396b518682bb3a47ba246684eb', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': '32013925', 'pmcid': None}, 'additional_info': {'summary': 'A detailed description of the dataset can be found in the Dataset section of the following paper: \\r\\n\\r\\nDavide Chicco, Giuseppe Jurman: \"Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone\". BMC Medical Informatics and Decision Making 20, 16 (2020). https://doi.org/10.1186/s12911-020-1023-5 \\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Thirteen (13) clinical features:\\n\\n- age: age of the patient (years)\\n- anaemia: decrease of red blood cells or hemoglobin (boolean)\\n- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)\\n- diabetes: if the patient has diabetes (boolean)\\n- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)\\n- high blood pressure: if the patient has hypertension (boolean)\\n- platelets: platelets in the blood (kiloplatelets/mL)\\n- sex: woman or man (binary)\\n- serum creatinine: level of serum creatinine in the blood (mg/dL)\\n- serum sodium: level of serum sodium in the blood (mEq/L)\\n- smoking: if the patient smokes or not (boolean)\\n- time: follow-up period (days)\\n- [target] death event: if the patient died during the follow-up period (boolean)\\n\\nFor more information, please check Table 1, Table 2, and Table 3 of the following paper: \\n\\nDavide Chicco, Giuseppe Jurman: \"Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone\". BMC Medical Informatics and Decision Making 20, 16 (2020). https://doi.org/10.1186/s12911-020-1023-5 \\n', 'citation': None}}\n",
      "Number of samples: 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m breast_cancer_clinical_records \u001B[38;5;241m=\u001B[39m load_uci_dataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/breast_cancer.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, repo_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of samples:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(breast_cancer_clinical_records))\n\u001B[0;32m----> 3\u001B[0m \u001B[43mbreast_cancer_clinical_records\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocess Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:29.936433Z",
     "start_time": "2025-01-15T10:39:29.933967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Handle missing values by dropping rows with any missing values\n",
    "breast_cancer_clinical_records = breast_cancer_clinical_records.dropna()\n",
    "print(\"Number of samples:\", len(breast_cancer_clinical_records))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 299\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:29.970705Z",
     "start_time": "2025-01-15T10:39:29.966764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separate features and target after dropping missing values\n",
    "X = breast_cancer_clinical_records.iloc[:, :-1]  # All columns except the last\n",
    "y = breast_cancer_clinical_records.iloc[:, -1]  # Last column as target\n",
    "\n",
    "# Encode target labels if necessary\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Assign Probabilities to Features using Mutual Information\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:29.996743Z",
     "start_time": "2025-01-15T10:39:29.982233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "probabilities = mutual_info / np.sum(mutual_info)  # Normalize to create a probability distribution\n",
    "\n",
    "print(\"Feature Probabilities (Mutual Information):\")\n",
    "print(probabilities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Probabilities (Mutual Information):\n",
      "[0.08333563 0.02014873 0.00677836 0.         0.18991753 0.\n",
      " 0.         0.19162453 0.         0.         0.         0.50819522]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Multiple Ensembles on Probabilistically Sampled Subsets\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:30.646823Z",
     "start_time": "2025-01-15T10:39:30.009256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_results = train_ensemble_models(X_train, X_test, y_train, y_test, probabilities, n_ensembles=5, n_features_sample=5, random_state=42, verbose=True)\n",
    "\n",
    "results_df = pd.DataFrame(ensemble_results)\n",
    "results_df.groupby(\"Classifier\")[\"Accuracy\"].mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ensemble 1/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8667\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8556\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 2/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8667\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8556\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 3/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8556\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 4/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8556\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 5/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8556\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8667\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8556\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "AdaBoost               0.846667\n",
       "Gradient Boosting      0.862222\n",
       "LDA                    0.800000\n",
       "Logistic Regression    0.806667\n",
       "Random Forest          0.837778\n",
       "SVM                    0.780000\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Analyze uncertainty in feature importance\n",
    "feature_frequency = compute_feature_frequency(ensemble_results, X_train.shape[1])\n",
    "\n",
    "print(\"\\nFeature Selection Frequency:\")\n",
    "print(feature_frequency)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gMeiCwsvlfh",
    "outputId": "75390383-eab7-49b9-98e0-b168a6cc86fc",
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:30.680305Z",
     "start_time": "2025-01-15T10:39:30.677616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Selection Frequency:\n",
      "[1.  0.4 0.6 0.  1.  0.  0.  1.  0.  0.  0.  1. ]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Assign probabilities to features using interaction scores"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:30.806510Z",
     "start_time": "2025-01-15T10:39:30.740761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Calculate pairwise interaction scores\n",
    "interaction_matrix = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for tree in rf.estimators_:\n",
    "    for feature_idx, importance in enumerate(tree.feature_importances_):\n",
    "        interaction_matrix[feature_idx] += importance\n",
    "\n",
    "interaction_scores = interaction_matrix.sum(axis=1) / rf.n_estimators\n",
    "probabilities = interaction_scores / interaction_scores.sum()\n",
    "\n",
    "print(\"Feature Probabilities (Interaction Scores):\")\n",
    "print(probabilities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Probabilities (Interaction Scores):\n",
      "[0.08910293 0.01823446 0.06889207 0.01136961 0.10625269 0.01338873\n",
      " 0.07031262 0.15944837 0.08441427 0.01277598 0.01005281 0.35575545]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Multiple Ensembles on Probabilistically Sampled Subsets\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:31.489810Z",
     "start_time": "2025-01-15T10:39:30.821453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_results = train_ensemble_models(X_train, X_test, y_train, y_test, probabilities, n_ensembles=5, n_features_sample=5, random_state=42, verbose=True)\n",
    "\n",
    "results_df = pd.DataFrame(ensemble_results)\n",
    "results_df.groupby(\"Classifier\")[\"Accuracy\"].mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ensemble 1/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.7778\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8111\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8556\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8222\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.6778\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8111\n",
      "\n",
      "Training Ensemble 2/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.7333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.7111\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.7000\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.7333\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.6778\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.7333\n",
      "\n",
      "Training Ensemble 3/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8778\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8222\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8222\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8111\n",
      "\n",
      "Training Ensemble 4/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8556\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8333\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8111\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.7889\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.7778\n",
      "\n",
      "Training Ensemble 5/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8000\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8444\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.7889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "AdaBoost               0.804444\n",
       "Gradient Boosting      0.815556\n",
       "LDA                    0.784444\n",
       "Logistic Regression    0.795556\n",
       "Random Forest          0.802222\n",
       "SVM                    0.715556\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze uncertainty in feature importance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:39:31.533295Z",
     "start_time": "2025-01-15T10:39:31.529975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze uncertainty in feature importance\n",
    "feature_frequency = compute_feature_frequency(ensemble_results, X_train.shape[1])\n",
    "\n",
    "print(\"\\nFeature Selection Frequency:\")\n",
    "print(feature_frequency)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Selection Frequency:\n",
      "[0.2 0.2 0.8 0.  0.8 0.2 0.4 0.8 0.8 0.  0.  0.8]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ]
}
