{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Probabilistic Feature Subset Selection with Ensemble Models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:16.313692Z",
     "start_time": "2025-01-15T11:12:15.757004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import compute_feature_frequency, load_uci_dataset, train_ensemble_models"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## UCI Heart Failure Clinical Records Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:16.319252Z",
     "start_time": "2025-01-15T11:12:16.316888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset from UCI Machine Learning Repository if it does not exist\n",
    "FILE_PATH = \"../data/heart_failure_clinical_records.csv\"\n",
    "\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    heart_failure_clinical_records_metadata, heart_failure_clinical_records = load_uci_dataset(repo_id=519)\n",
    "    print(heart_failure_clinical_records_metadata)\n",
    "    heart_failure_clinical_records.to_csv(FILE_PATH, index=False)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:16.362964Z",
     "start_time": "2025-01-15T11:12:16.354438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset from CSV file\n",
    "heart_failure_clinical_records = pd.read_csv(FILE_PATH)\n",
    "print(\"Number of samples:\", len(heart_failure_clinical_records))\n",
    "heart_failure_clinical_records.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  death_event  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>death_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocess Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:16.390669Z",
     "start_time": "2025-01-15T11:12:16.388484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Handle missing values by dropping rows with any missing values\n",
    "heart_failure_clinical_records = heart_failure_clinical_records.dropna()\n",
    "print(\"Number of samples:\", len(heart_failure_clinical_records))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 299\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:16.420238Z",
     "start_time": "2025-01-15T11:12:16.416784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separate features and target after dropping missing values\n",
    "X = heart_failure_clinical_records.iloc[:, :-1]  # All columns except the last\n",
    "y = heart_failure_clinical_records.iloc[:, -1]  # Last column as target\n",
    "\n",
    "# Encode target labels if necessary\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Assign Probabilities to Features using Mutual Information\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:16.438731Z",
     "start_time": "2025-01-15T11:12:16.425714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "probabilities = mutual_info / np.sum(mutual_info)  # Normalize to create a probability distribution\n",
    "\n",
    "print(\"Feature Probabilities (Mutual Information):\")\n",
    "print(probabilities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Probabilities (Mutual Information):\n",
      "[0.09432641 0.         0.01222827 0.10784709 0.17183416 0.\n",
      " 0.         0.18186509 0.         0.01304648 0.04477241 0.37408009]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Multiple Ensembles on Probabilistically Sampled Subsets\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:17.072024Z",
     "start_time": "2025-01-15T11:12:16.448969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_results = train_ensemble_models(X_train, X_test, y_train, y_test, probabilities, n_ensembles=5, n_features_sample=5, random_state=42, verbose=True)\n",
    "\n",
    "results_df = pd.DataFrame(ensemble_results)\n",
    "results_df.groupby(\"Classifier\")[\"Accuracy\"].mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ensemble 1/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8444\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8222\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 2/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8556\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8556\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7444\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 3/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8444\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 4/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8333\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8444\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 5/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8444\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8222\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "AdaBoost               0.833333\n",
       "Gradient Boosting      0.846667\n",
       "LDA                    0.800000\n",
       "Logistic Regression    0.806667\n",
       "Random Forest          0.831111\n",
       "SVM                    0.815556\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Analyze uncertainty in feature importance\n",
    "feature_frequency = compute_feature_frequency(ensemble_results, X_train.shape[1])\n",
    "\n",
    "print(\"\\nFeature Selection Frequency:\")\n",
    "print(feature_frequency)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gMeiCwsvlfh",
    "outputId": "75390383-eab7-49b9-98e0-b168a6cc86fc",
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:17.104582Z",
     "start_time": "2025-01-15T11:12:17.102263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Selection Frequency:\n",
      "[1.  0.  0.2 0.4 1.  0.  0.  1.  0.  0.  0.4 1. ]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Assign probabilities to features using interaction scores"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:17.211323Z",
     "start_time": "2025-01-15T11:12:17.153795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Calculate pairwise interaction scores\n",
    "interaction_matrix = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for tree in rf.estimators_:\n",
    "    for feature_idx, importance in enumerate(tree.feature_importances_):\n",
    "        interaction_matrix[feature_idx] += importance\n",
    "\n",
    "interaction_scores = interaction_matrix.sum(axis=1) / rf.n_estimators\n",
    "probabilities = interaction_scores / interaction_scores.sum()\n",
    "\n",
    "print(\"Feature Probabilities (Interaction Scores):\")\n",
    "print(probabilities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Probabilities (Interaction Scores):\n",
      "[0.08910293 0.01823446 0.06889207 0.01136961 0.10625269 0.01338873\n",
      " 0.07031262 0.15944837 0.08441427 0.01277598 0.01005281 0.35575545]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Multiple Ensembles on Probabilistically Sampled Subsets\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:17.851794Z",
     "start_time": "2025-01-15T11:12:17.222342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_results = train_ensemble_models(X_train, X_test, y_train, y_test, probabilities, n_ensembles=5, n_features_sample=5, random_state=42, verbose=True)\n",
    "\n",
    "results_df = pd.DataFrame(ensemble_results)\n",
    "results_df.groupby(\"Classifier\")[\"Accuracy\"].mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ensemble 1/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8444\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8111\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n",
      "\n",
      "Training Ensemble 2/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8556\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8333\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8111\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.7889\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.7778\n",
      "\n",
      "Training Ensemble 3/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8111\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8000\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8000\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.7778\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7222\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.7889\n",
      "\n",
      "Training Ensemble 4/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8222\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8111\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8333\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.7889\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8222\n",
      "\n",
      "Training Ensemble 5/5...\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8444\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.8556\n",
      "Training AdaBoost...\n",
      "AdaBoost Accuracy: 0.8333\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8333\n",
      "Training LDA...\n",
      "LDA Accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "AdaBoost               0.822222\n",
       "Gradient Boosting      0.828889\n",
       "LDA                    0.797778\n",
       "Logistic Regression    0.802222\n",
       "Random Forest          0.831111\n",
       "SVM                    0.782222\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze uncertainty in feature importance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:17.887061Z",
     "start_time": "2025-01-15T11:12:17.884413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze uncertainty in feature importance\n",
    "feature_frequency = compute_feature_frequency(ensemble_results, X_train.shape[1])\n",
    "\n",
    "print(\"\\nFeature Selection Frequency:\")\n",
    "print(feature_frequency)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Selection Frequency:\n",
      "[0.6 0.6 0.4 0.2 0.6 0.2 0.  0.8 0.4 0.2 0.  1. ]\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ]
}
